# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10V_EQyrzFWORmxkHiFG7fglKwqE4dK_e
"""

# Necessaary import files:
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn import metrics
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
import math
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten
import io
from google.colab import files
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D
from keras.utils import to_categorical
from keras.datasets import mnist
from keras.layers.normalization import BatchNormalization

"""Hand written dataset"""

# Train test split via the kaggle import:
(X_train, y_train), (X_test, y_test) = mnist.load_data()

# Set up the x variables
X_train = X_train.reshape(60000,28,28,1)
X_test = X_test.reshape(10000,28,28,1)

# Set up y variables via one-hot encoding:
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# Build Model:
model = Sequential()s

# Add layers:
model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))
model.add(Conv2D(32, kernel_size=3, activation='relu'))
model.add(Flatten())
model.add(Dense(10, activation='softmax'))

# Compile Model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train model
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)

"""Skin Cancer Data Set"""

# repeat same process with new dataset (will clump code into one cell this time around since it is step by step in previous section):
df = pd.read_csv('hmnist_28_28_L.csv')

# Ensure dataframe is well downloaded
print(df.head() )

# Set up x and y variables:
x = np.array(df.drop(["label"], axis=1))
y = np.array(df["label"])

x = x.reshape(10015, 28, 28, 1)

# One hot encode y variables: When I one hot encoded I kept getting an error due to different shapes, so I am not one hot encding and using sparse_categorical_crossentropy instead
y = to_categorical(y)

# train/test split the data (test set is also considered a holdout set):
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20)

# Train the model:
model = Sequential()

from keras.regularizers import l2

# Model layers
model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1), name='fc1', bias_regularizer=l2(0.01)))
model.add(Conv2D(32, kernel_size=3, activation='relu', name='fc2', bias_regularizer=l2(0.01)))
model.add(MaxPooling2D( ))
model.add(BatchNormalization())
model.add(MaxPooling2D())
model.add(Flatten())
model.add(Dense(7, activation='sigmoid', bias_regularizer=l2(0.01)))

# Compile model:
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train model
output = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=200)