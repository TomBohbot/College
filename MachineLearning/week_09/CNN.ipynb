{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcKr7CRH_0BO"
      },
      "source": [
        "# Necessaary import files:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "import io\n",
        "from google.colab import files\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JvBZxArG4iq"
      },
      "source": [
        "Hand written dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G23InxuBEy9n"
      },
      "source": [
        "# Train test split via the kaggle import:\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Set up the x variables\n",
        "X_train = X_train.reshape(60000,28,28,1)\n",
        "X_test = X_test.reshape(10000,28,28,1)\n",
        "\n",
        "# Set up y variables via one-hot encoding:\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7_ZLuo3E7l5",
        "outputId": "77d32581-0f70-4b8a-c55b-890e8f08ed84"
      },
      "source": [
        "# Build Model:\n",
        "model = Sequential()s\n",
        "\n",
        "# Add layers:\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 155s 82ms/step - loss: 0.6886 - accuracy: 0.9222 - val_loss: 0.0935 - val_accuracy: 0.9743\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 154s 82ms/step - loss: 0.0657 - accuracy: 0.9796 - val_loss: 0.0748 - val_accuracy: 0.9770\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 154s 82ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.0819 - val_accuracy: 0.9772\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f483bd426d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHBkvlI1O9EG"
      },
      "source": [
        "Skin Cancer Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N_fXIhbFtoQ",
        "outputId": "5a568800-4f1e-4a12-9f4a-f6cb98672efd"
      },
      "source": [
        "# repeat same process with new dataset (will clump code into one cell this time around since it is step by step in previous section):\n",
        "df = pd.read_csv('hmnist_28_28_L.csv')\n",
        "\n",
        "# Ensure dataframe is well downloaded\n",
        "print(df.head() )\n",
        "\n",
        "# Set up x and y variables:\n",
        "x = np.array(df.drop([\"label\"], axis=1))\n",
        "y = np.array(df[\"label\"])\n",
        "\n",
        "x = x.reshape(10015, 28, 28, 1)\n",
        "\n",
        "# One hot encode y variables: When I one hot encoded I kept getting an error due to different shapes, so I am not one hot encding and using sparse_categorical_crossentropy instead\n",
        "y = to_categorical(y)\n",
        "\n",
        "# train/test split the data (test set is also considered a holdout set):\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20)\n",
        "\n",
        "# Train the model:\n",
        "model = Sequential()\n",
        "\n",
        "from keras.regularizers import l2\n",
        "\n",
        "# Model layers\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1), name='fc1', bias_regularizer=l2(0.01)))\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu', name='fc2', bias_regularizer=l2(0.01)))\n",
        "model.add(MaxPooling2D( ))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(7, activation='sigmoid', bias_regularizer=l2(0.01)))\n",
        "\n",
        "# Compile model:\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "output = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=200)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   pixel0000  pixel0001  pixel0002  ...  pixel0782  pixel0783  label\n",
            "0        169        171        170  ...        159        165      2\n",
            "1         19         57        105  ...         18         18      2\n",
            "2        155        163        161  ...        136        115      2\n",
            "3         25         71        116  ...         16         16      2\n",
            "4        129        162        181  ...        147         88      2\n",
            "\n",
            "[5 rows x 785 columns]\n",
            "Epoch 1/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.3177 - accuracy: 0.6342 - val_loss: 0.4930 - val_accuracy: 0.6755\n",
            "Epoch 2/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.2265 - accuracy: 0.6846 - val_loss: 0.2488 - val_accuracy: 0.6875\n",
            "Epoch 3/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.2201 - accuracy: 0.6965 - val_loss: 0.2125 - val_accuracy: 0.7084\n",
            "Epoch 4/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.2102 - accuracy: 0.6975 - val_loss: 0.2949 - val_accuracy: 0.6840\n",
            "Epoch 5/200\n",
            "251/251 [==============================] - 21s 84ms/step - loss: 0.2105 - accuracy: 0.7000 - val_loss: 0.2943 - val_accuracy: 0.6880\n",
            "Epoch 6/200\n",
            "251/251 [==============================] - 21s 84ms/step - loss: 0.2038 - accuracy: 0.7076 - val_loss: 0.2251 - val_accuracy: 0.6980\n",
            "Epoch 7/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.2034 - accuracy: 0.7114 - val_loss: 0.2598 - val_accuracy: 0.6575\n",
            "Epoch 8/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.1967 - accuracy: 0.7207 - val_loss: 0.3174 - val_accuracy: 0.5637\n",
            "Epoch 9/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.1951 - accuracy: 0.7237 - val_loss: 0.8512 - val_accuracy: 0.2157\n",
            "Epoch 10/200\n",
            "251/251 [==============================] - 21s 84ms/step - loss: 0.1908 - accuracy: 0.7295 - val_loss: 0.2661 - val_accuracy: 0.6835\n",
            "Epoch 11/200\n",
            "251/251 [==============================] - 21s 84ms/step - loss: 0.1888 - accuracy: 0.7279 - val_loss: 0.2036 - val_accuracy: 0.7074\n",
            "Epoch 12/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.1857 - accuracy: 0.7365 - val_loss: 0.2260 - val_accuracy: 0.6815\n",
            "Epoch 13/200\n",
            "251/251 [==============================] - 21s 84ms/step - loss: 0.1898 - accuracy: 0.7315 - val_loss: 0.2358 - val_accuracy: 0.6630\n",
            "Epoch 14/200\n",
            "251/251 [==============================] - 21s 84ms/step - loss: 0.1797 - accuracy: 0.7457 - val_loss: 0.2109 - val_accuracy: 0.7094\n",
            "Epoch 15/200\n",
            "251/251 [==============================] - 21s 84ms/step - loss: 0.1786 - accuracy: 0.7471 - val_loss: 0.2415 - val_accuracy: 0.6855\n",
            "Epoch 16/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.1712 - accuracy: 0.7517 - val_loss: 0.2380 - val_accuracy: 0.6585\n",
            "Epoch 17/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.1747 - accuracy: 0.7510 - val_loss: 0.2780 - val_accuracy: 0.6785\n",
            "Epoch 18/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.1763 - accuracy: 0.7494 - val_loss: 0.5116 - val_accuracy: 0.4968\n",
            "Epoch 19/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.1736 - accuracy: 0.7584 - val_loss: 0.2731 - val_accuracy: 0.6375\n",
            "Epoch 20/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.1692 - accuracy: 0.7632 - val_loss: 0.2637 - val_accuracy: 0.6880\n",
            "Epoch 21/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.1650 - accuracy: 0.7646 - val_loss: 0.2627 - val_accuracy: 0.6875\n",
            "Epoch 22/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.1660 - accuracy: 0.7728 - val_loss: 0.2171 - val_accuracy: 0.7084\n",
            "Epoch 23/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.1616 - accuracy: 0.7702 - val_loss: 0.2293 - val_accuracy: 0.6825\n",
            "Epoch 24/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.1604 - accuracy: 0.7752 - val_loss: 0.2359 - val_accuracy: 0.6760\n",
            "Epoch 25/200\n",
            "251/251 [==============================] - 21s 83ms/step - loss: 0.1565 - accuracy: 0.7815 - val_loss: 0.2581 - val_accuracy: 0.6500\n",
            "Epoch 26/200\n",
            "251/251 [==============================] - 21s 83ms/step - loss: 0.1580 - accuracy: 0.7824 - val_loss: 0.2334 - val_accuracy: 0.7069\n",
            "Epoch 27/200\n",
            "251/251 [==============================] - 21s 83ms/step - loss: 0.1562 - accuracy: 0.7797 - val_loss: 0.2220 - val_accuracy: 0.6990\n",
            "Epoch 28/200\n",
            "251/251 [==============================] - 21s 83ms/step - loss: 0.1522 - accuracy: 0.7941 - val_loss: 0.2347 - val_accuracy: 0.7069\n",
            "Epoch 29/200\n",
            "251/251 [==============================] - 21s 83ms/step - loss: 0.1525 - accuracy: 0.7876 - val_loss: 0.2170 - val_accuracy: 0.7149\n",
            "Epoch 30/200\n",
            "251/251 [==============================] - 21s 83ms/step - loss: 0.1505 - accuracy: 0.7948 - val_loss: 0.2321 - val_accuracy: 0.6950\n",
            "Epoch 31/200\n",
            "251/251 [==============================] - 21s 83ms/step - loss: 0.1503 - accuracy: 0.7952 - val_loss: 0.2391 - val_accuracy: 0.7064\n",
            "Epoch 32/200\n",
            "251/251 [==============================] - 21s 84ms/step - loss: 0.1482 - accuracy: 0.7967 - val_loss: 0.2367 - val_accuracy: 0.7084\n",
            "Epoch 33/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1446 - accuracy: 0.8026 - val_loss: 0.2559 - val_accuracy: 0.6605\n",
            "Epoch 34/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1423 - accuracy: 0.8124 - val_loss: 0.2401 - val_accuracy: 0.6950\n",
            "Epoch 35/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.1393 - accuracy: 0.8121 - val_loss: 0.2328 - val_accuracy: 0.7099\n",
            "Epoch 36/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1377 - accuracy: 0.8133 - val_loss: 0.3434 - val_accuracy: 0.5736\n",
            "Epoch 37/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1352 - accuracy: 0.8205 - val_loss: 0.2675 - val_accuracy: 0.6870\n",
            "Epoch 38/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.1383 - accuracy: 0.8174 - val_loss: 0.2475 - val_accuracy: 0.6965\n",
            "Epoch 39/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.1333 - accuracy: 0.8226 - val_loss: 0.2439 - val_accuracy: 0.6885\n",
            "Epoch 40/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.1348 - accuracy: 0.8182 - val_loss: 0.2796 - val_accuracy: 0.6745\n",
            "Epoch 41/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1345 - accuracy: 0.8225 - val_loss: 0.2413 - val_accuracy: 0.6995\n",
            "Epoch 42/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1301 - accuracy: 0.8287 - val_loss: 0.2641 - val_accuracy: 0.6965\n",
            "Epoch 43/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.1279 - accuracy: 0.8325 - val_loss: 0.3215 - val_accuracy: 0.6910\n",
            "Epoch 44/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1278 - accuracy: 0.8351 - val_loss: 0.3909 - val_accuracy: 0.5327\n",
            "Epoch 45/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.1241 - accuracy: 0.8425 - val_loss: 0.2574 - val_accuracy: 0.6835\n",
            "Epoch 46/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1240 - accuracy: 0.8415 - val_loss: 0.2746 - val_accuracy: 0.6880\n",
            "Epoch 47/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1216 - accuracy: 0.8397 - val_loss: 0.2542 - val_accuracy: 0.6855\n",
            "Epoch 48/200\n",
            "251/251 [==============================] - 21s 86ms/step - loss: 0.1189 - accuracy: 0.8501 - val_loss: 0.2673 - val_accuracy: 0.6915\n",
            "Epoch 49/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1190 - accuracy: 0.8483 - val_loss: 0.2568 - val_accuracy: 0.6990\n",
            "Epoch 50/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1186 - accuracy: 0.8488 - val_loss: 0.2709 - val_accuracy: 0.6790\n",
            "Epoch 51/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1172 - accuracy: 0.8502 - val_loss: 0.2750 - val_accuracy: 0.6615\n",
            "Epoch 52/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1123 - accuracy: 0.8533 - val_loss: 0.2918 - val_accuracy: 0.6630\n",
            "Epoch 53/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.1098 - accuracy: 0.8627 - val_loss: 0.2632 - val_accuracy: 0.6900\n",
            "Epoch 54/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1115 - accuracy: 0.8617 - val_loss: 0.2655 - val_accuracy: 0.6950\n",
            "Epoch 55/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1114 - accuracy: 0.8619 - val_loss: 0.3859 - val_accuracy: 0.6840\n",
            "Epoch 56/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1123 - accuracy: 0.8607 - val_loss: 0.2863 - val_accuracy: 0.6800\n",
            "Epoch 57/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1009 - accuracy: 0.8709 - val_loss: 0.3042 - val_accuracy: 0.6695\n",
            "Epoch 58/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1068 - accuracy: 0.8670 - val_loss: 0.3092 - val_accuracy: 0.6520\n",
            "Epoch 59/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1046 - accuracy: 0.8762 - val_loss: 0.3090 - val_accuracy: 0.6345\n",
            "Epoch 60/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1056 - accuracy: 0.8754 - val_loss: 0.3251 - val_accuracy: 0.6385\n",
            "Epoch 61/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.0995 - accuracy: 0.8860 - val_loss: 0.3016 - val_accuracy: 0.6940\n",
            "Epoch 62/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.1005 - accuracy: 0.8804 - val_loss: 0.3210 - val_accuracy: 0.6251\n",
            "Epoch 63/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.1015 - accuracy: 0.8755 - val_loss: 0.3307 - val_accuracy: 0.6465\n",
            "Epoch 64/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.0987 - accuracy: 0.8823 - val_loss: 0.2835 - val_accuracy: 0.6880\n",
            "Epoch 65/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.0943 - accuracy: 0.8891 - val_loss: 0.3007 - val_accuracy: 0.6730\n",
            "Epoch 66/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.1021 - accuracy: 0.8777 - val_loss: 0.3147 - val_accuracy: 0.6490\n",
            "Epoch 67/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.0963 - accuracy: 0.8834 - val_loss: 0.3570 - val_accuracy: 0.6950\n",
            "Epoch 68/200\n",
            "251/251 [==============================] - 21s 86ms/step - loss: 0.0934 - accuracy: 0.8922 - val_loss: 0.3029 - val_accuracy: 0.6765\n",
            "Epoch 69/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.0935 - accuracy: 0.8858 - val_loss: 0.3301 - val_accuracy: 0.6895\n",
            "Epoch 70/200\n",
            "251/251 [==============================] - 21s 83ms/step - loss: 0.0912 - accuracy: 0.8973 - val_loss: 0.3106 - val_accuracy: 0.6750\n",
            "Epoch 71/200\n",
            "251/251 [==============================] - 21s 83ms/step - loss: 0.0943 - accuracy: 0.8934 - val_loss: 0.3172 - val_accuracy: 0.6775\n",
            "Epoch 72/200\n",
            "251/251 [==============================] - 21s 85ms/step - loss: 0.0870 - accuracy: 0.8991 - val_loss: 0.3481 - val_accuracy: 0.6385\n",
            "Epoch 73/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.0905 - accuracy: 0.8936 - val_loss: 0.3220 - val_accuracy: 0.6595\n",
            "Epoch 74/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.0876 - accuracy: 0.9023 - val_loss: 0.3544 - val_accuracy: 0.6360\n",
            "Epoch 75/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.0868 - accuracy: 0.8975 - val_loss: 0.3289 - val_accuracy: 0.6615\n",
            "Epoch 76/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.0894 - accuracy: 0.8965 - val_loss: 0.3242 - val_accuracy: 0.6730\n",
            "Epoch 77/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0823 - accuracy: 0.9034 - val_loss: 0.3263 - val_accuracy: 0.6950\n",
            "Epoch 78/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.0828 - accuracy: 0.9092 - val_loss: 0.3390 - val_accuracy: 0.6770\n",
            "Epoch 79/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.0840 - accuracy: 0.9033 - val_loss: 0.3382 - val_accuracy: 0.6715\n",
            "Epoch 80/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.0841 - accuracy: 0.9061 - val_loss: 0.3430 - val_accuracy: 0.6875\n",
            "Epoch 81/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.0867 - accuracy: 0.8976 - val_loss: 0.5510 - val_accuracy: 0.5746\n",
            "Epoch 82/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0821 - accuracy: 0.9030 - val_loss: 0.3356 - val_accuracy: 0.6565\n",
            "Epoch 83/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.0804 - accuracy: 0.9104 - val_loss: 0.3445 - val_accuracy: 0.6805\n",
            "Epoch 84/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.0776 - accuracy: 0.9111 - val_loss: 0.3627 - val_accuracy: 0.6500\n",
            "Epoch 85/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.0793 - accuracy: 0.9125 - val_loss: 0.3918 - val_accuracy: 0.6510\n",
            "Epoch 86/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.0786 - accuracy: 0.9172 - val_loss: 0.3998 - val_accuracy: 0.6021\n",
            "Epoch 87/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.0765 - accuracy: 0.9148 - val_loss: 0.3814 - val_accuracy: 0.6645\n",
            "Epoch 88/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0749 - accuracy: 0.9225 - val_loss: 0.3740 - val_accuracy: 0.6925\n",
            "Epoch 89/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0764 - accuracy: 0.9145 - val_loss: 0.3598 - val_accuracy: 0.6800\n",
            "Epoch 90/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0713 - accuracy: 0.9253 - val_loss: 0.3604 - val_accuracy: 0.6650\n",
            "Epoch 91/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0724 - accuracy: 0.9222 - val_loss: 0.3677 - val_accuracy: 0.6760\n",
            "Epoch 92/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0696 - accuracy: 0.9254 - val_loss: 0.4100 - val_accuracy: 0.6106\n",
            "Epoch 93/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0692 - accuracy: 0.9292 - val_loss: 0.3667 - val_accuracy: 0.6610\n",
            "Epoch 94/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0740 - accuracy: 0.9223 - val_loss: 0.3880 - val_accuracy: 0.6675\n",
            "Epoch 95/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0721 - accuracy: 0.9225 - val_loss: 0.3872 - val_accuracy: 0.6640\n",
            "Epoch 96/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0672 - accuracy: 0.9272 - val_loss: 0.4045 - val_accuracy: 0.6730\n",
            "Epoch 97/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0696 - accuracy: 0.9234 - val_loss: 0.4014 - val_accuracy: 0.6835\n",
            "Epoch 98/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0673 - accuracy: 0.9309 - val_loss: 0.3829 - val_accuracy: 0.6790\n",
            "Epoch 99/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0666 - accuracy: 0.9306 - val_loss: 0.3837 - val_accuracy: 0.6740\n",
            "Epoch 100/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0674 - accuracy: 0.9332 - val_loss: 0.3967 - val_accuracy: 0.6770\n",
            "Epoch 101/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0661 - accuracy: 0.9331 - val_loss: 0.4087 - val_accuracy: 0.6500\n",
            "Epoch 102/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0683 - accuracy: 0.9323 - val_loss: 0.5065 - val_accuracy: 0.6855\n",
            "Epoch 103/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0636 - accuracy: 0.9330 - val_loss: 0.4043 - val_accuracy: 0.6660\n",
            "Epoch 104/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0640 - accuracy: 0.9340 - val_loss: 0.4460 - val_accuracy: 0.6910\n",
            "Epoch 105/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0671 - accuracy: 0.9334 - val_loss: 0.4477 - val_accuracy: 0.6181\n",
            "Epoch 106/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0595 - accuracy: 0.9405 - val_loss: 0.4278 - val_accuracy: 0.6365\n",
            "Epoch 107/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0606 - accuracy: 0.9437 - val_loss: 0.4233 - val_accuracy: 0.6445\n",
            "Epoch 108/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0695 - accuracy: 0.9269 - val_loss: 0.4489 - val_accuracy: 0.6241\n",
            "Epoch 109/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0628 - accuracy: 0.9340 - val_loss: 0.4226 - val_accuracy: 0.6620\n",
            "Epoch 110/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0613 - accuracy: 0.9385 - val_loss: 0.4140 - val_accuracy: 0.6800\n",
            "Epoch 111/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0637 - accuracy: 0.9378 - val_loss: 0.4222 - val_accuracy: 0.6750\n",
            "Epoch 112/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0565 - accuracy: 0.9466 - val_loss: 0.4276 - val_accuracy: 0.6705\n",
            "Epoch 113/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0583 - accuracy: 0.9433 - val_loss: 0.4294 - val_accuracy: 0.6825\n",
            "Epoch 114/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0512 - accuracy: 0.9496 - val_loss: 0.4709 - val_accuracy: 0.6560\n",
            "Epoch 115/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0595 - accuracy: 0.9453 - val_loss: 0.4406 - val_accuracy: 0.6665\n",
            "Epoch 116/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0579 - accuracy: 0.9443 - val_loss: 0.4544 - val_accuracy: 0.6730\n",
            "Epoch 117/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0566 - accuracy: 0.9436 - val_loss: 0.4681 - val_accuracy: 0.6895\n",
            "Epoch 118/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0562 - accuracy: 0.9469 - val_loss: 0.4664 - val_accuracy: 0.6890\n",
            "Epoch 119/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0602 - accuracy: 0.9430 - val_loss: 0.4587 - val_accuracy: 0.6745\n",
            "Epoch 120/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0580 - accuracy: 0.9444 - val_loss: 0.4621 - val_accuracy: 0.6850\n",
            "Epoch 121/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0555 - accuracy: 0.9459 - val_loss: 0.4733 - val_accuracy: 0.6795\n",
            "Epoch 122/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0526 - accuracy: 0.9510 - val_loss: 0.4749 - val_accuracy: 0.6865\n",
            "Epoch 123/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0528 - accuracy: 0.9505 - val_loss: 0.4913 - val_accuracy: 0.6675\n",
            "Epoch 124/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0553 - accuracy: 0.9494 - val_loss: 0.4867 - val_accuracy: 0.6805\n",
            "Epoch 125/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0549 - accuracy: 0.9490 - val_loss: 0.4634 - val_accuracy: 0.6625\n",
            "Epoch 126/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0537 - accuracy: 0.9501 - val_loss: 0.4880 - val_accuracy: 0.6380\n",
            "Epoch 127/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0500 - accuracy: 0.9548 - val_loss: 0.4891 - val_accuracy: 0.6785\n",
            "Epoch 128/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0495 - accuracy: 0.9554 - val_loss: 0.4811 - val_accuracy: 0.6825\n",
            "Epoch 129/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.0538 - accuracy: 0.9536 - val_loss: 0.4965 - val_accuracy: 0.6600\n",
            "Epoch 130/200\n",
            "251/251 [==============================] - 21s 86ms/step - loss: 0.0513 - accuracy: 0.9571 - val_loss: 0.4930 - val_accuracy: 0.6830\n",
            "Epoch 131/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.0490 - accuracy: 0.9558 - val_loss: 0.4864 - val_accuracy: 0.6535\n",
            "Epoch 132/200\n",
            "251/251 [==============================] - 22s 86ms/step - loss: 0.0462 - accuracy: 0.9618 - val_loss: 0.5010 - val_accuracy: 0.6790\n",
            "Epoch 133/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0498 - accuracy: 0.9574 - val_loss: 0.5403 - val_accuracy: 0.6870\n",
            "Epoch 134/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0475 - accuracy: 0.9636 - val_loss: 0.5041 - val_accuracy: 0.6700\n",
            "Epoch 135/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0504 - accuracy: 0.9549 - val_loss: 0.6089 - val_accuracy: 0.6286\n",
            "Epoch 136/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0515 - accuracy: 0.9509 - val_loss: 0.4900 - val_accuracy: 0.6745\n",
            "Epoch 137/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0452 - accuracy: 0.9583 - val_loss: 0.5030 - val_accuracy: 0.6625\n",
            "Epoch 138/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0462 - accuracy: 0.9609 - val_loss: 0.5109 - val_accuracy: 0.6610\n",
            "Epoch 139/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0494 - accuracy: 0.9569 - val_loss: 0.5233 - val_accuracy: 0.6770\n",
            "Epoch 140/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0443 - accuracy: 0.9620 - val_loss: 0.5338 - val_accuracy: 0.6395\n",
            "Epoch 141/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0482 - accuracy: 0.9573 - val_loss: 0.5191 - val_accuracy: 0.6650\n",
            "Epoch 142/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0475 - accuracy: 0.9606 - val_loss: 0.5512 - val_accuracy: 0.6805\n",
            "Epoch 143/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0496 - accuracy: 0.9532 - val_loss: 0.5208 - val_accuracy: 0.6600\n",
            "Epoch 144/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0439 - accuracy: 0.9628 - val_loss: 0.5285 - val_accuracy: 0.6480\n",
            "Epoch 145/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0415 - accuracy: 0.9686 - val_loss: 0.5448 - val_accuracy: 0.6440\n",
            "Epoch 146/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0513 - accuracy: 0.9536 - val_loss: 0.5374 - val_accuracy: 0.6805\n",
            "Epoch 147/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0476 - accuracy: 0.9585 - val_loss: 0.5350 - val_accuracy: 0.6585\n",
            "Epoch 148/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0430 - accuracy: 0.9644 - val_loss: 0.5503 - val_accuracy: 0.6805\n",
            "Epoch 149/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0437 - accuracy: 0.9625 - val_loss: 0.5670 - val_accuracy: 0.6730\n",
            "Epoch 150/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0415 - accuracy: 0.9667 - val_loss: 0.5812 - val_accuracy: 0.6650\n",
            "Epoch 151/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0546 - accuracy: 0.9463 - val_loss: 0.5585 - val_accuracy: 0.6316\n",
            "Epoch 152/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0456 - accuracy: 0.9615 - val_loss: 0.5532 - val_accuracy: 0.6765\n",
            "Epoch 153/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0401 - accuracy: 0.9658 - val_loss: 0.5506 - val_accuracy: 0.6580\n",
            "Epoch 154/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0399 - accuracy: 0.9684 - val_loss: 0.6135 - val_accuracy: 0.6825\n",
            "Epoch 155/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0442 - accuracy: 0.9630 - val_loss: 0.5595 - val_accuracy: 0.6570\n",
            "Epoch 156/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0418 - accuracy: 0.9664 - val_loss: 0.5968 - val_accuracy: 0.6895\n",
            "Epoch 157/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0440 - accuracy: 0.9630 - val_loss: 0.5788 - val_accuracy: 0.6510\n",
            "Epoch 158/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0462 - accuracy: 0.9606 - val_loss: 0.6355 - val_accuracy: 0.6850\n",
            "Epoch 159/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0416 - accuracy: 0.9678 - val_loss: 0.5681 - val_accuracy: 0.6530\n",
            "Epoch 160/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0372 - accuracy: 0.9723 - val_loss: 0.5974 - val_accuracy: 0.6365\n",
            "Epoch 161/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0426 - accuracy: 0.9639 - val_loss: 0.5743 - val_accuracy: 0.6715\n",
            "Epoch 162/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0423 - accuracy: 0.9653 - val_loss: 0.5692 - val_accuracy: 0.6675\n",
            "Epoch 163/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0346 - accuracy: 0.9749 - val_loss: 0.6151 - val_accuracy: 0.6855\n",
            "Epoch 164/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0394 - accuracy: 0.9692 - val_loss: 0.6638 - val_accuracy: 0.5871\n",
            "Epoch 165/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0430 - accuracy: 0.9629 - val_loss: 0.6284 - val_accuracy: 0.6301\n",
            "Epoch 166/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0357 - accuracy: 0.9679 - val_loss: 0.5832 - val_accuracy: 0.6720\n",
            "Epoch 167/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0392 - accuracy: 0.9707 - val_loss: 0.5953 - val_accuracy: 0.6515\n",
            "Epoch 168/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0370 - accuracy: 0.9705 - val_loss: 0.6200 - val_accuracy: 0.6770\n",
            "Epoch 169/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0421 - accuracy: 0.9678 - val_loss: 0.6149 - val_accuracy: 0.6750\n",
            "Epoch 170/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0400 - accuracy: 0.9624 - val_loss: 0.6516 - val_accuracy: 0.6830\n",
            "Epoch 171/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0397 - accuracy: 0.9666 - val_loss: 0.5900 - val_accuracy: 0.6625\n",
            "Epoch 172/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0374 - accuracy: 0.9707 - val_loss: 0.6600 - val_accuracy: 0.6825\n",
            "Epoch 173/200\n",
            "251/251 [==============================] - 22s 87ms/step - loss: 0.0332 - accuracy: 0.9738 - val_loss: 0.6208 - val_accuracy: 0.6850\n",
            "Epoch 174/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0330 - accuracy: 0.9791 - val_loss: 0.6574 - val_accuracy: 0.6760\n",
            "Epoch 175/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0434 - accuracy: 0.9633 - val_loss: 0.6340 - val_accuracy: 0.6575\n",
            "Epoch 176/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0355 - accuracy: 0.9741 - val_loss: 0.6397 - val_accuracy: 0.6620\n",
            "Epoch 177/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0336 - accuracy: 0.9763 - val_loss: 0.6395 - val_accuracy: 0.6685\n",
            "Epoch 178/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0326 - accuracy: 0.9749 - val_loss: 0.6795 - val_accuracy: 0.6151\n",
            "Epoch 179/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0379 - accuracy: 0.9694 - val_loss: 0.6316 - val_accuracy: 0.6575\n",
            "Epoch 180/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0335 - accuracy: 0.9747 - val_loss: 0.6657 - val_accuracy: 0.6640\n",
            "Epoch 181/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0383 - accuracy: 0.9692 - val_loss: 0.7439 - val_accuracy: 0.6895\n",
            "Epoch 182/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0383 - accuracy: 0.9691 - val_loss: 0.6426 - val_accuracy: 0.6730\n",
            "Epoch 183/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0313 - accuracy: 0.9772 - val_loss: 0.6477 - val_accuracy: 0.6560\n",
            "Epoch 184/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0365 - accuracy: 0.9729 - val_loss: 0.6414 - val_accuracy: 0.6385\n",
            "Epoch 185/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0399 - accuracy: 0.9689 - val_loss: 0.6421 - val_accuracy: 0.6575\n",
            "Epoch 186/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0375 - accuracy: 0.9717 - val_loss: 0.6695 - val_accuracy: 0.6535\n",
            "Epoch 187/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0360 - accuracy: 0.9743 - val_loss: 0.6417 - val_accuracy: 0.6830\n",
            "Epoch 188/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0338 - accuracy: 0.9729 - val_loss: 0.6752 - val_accuracy: 0.6555\n",
            "Epoch 189/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0344 - accuracy: 0.9752 - val_loss: 0.6553 - val_accuracy: 0.6650\n",
            "Epoch 190/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0325 - accuracy: 0.9760 - val_loss: 0.6641 - val_accuracy: 0.6710\n",
            "Epoch 191/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0279 - accuracy: 0.9799 - val_loss: 0.7123 - val_accuracy: 0.6835\n",
            "Epoch 192/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0323 - accuracy: 0.9792 - val_loss: 0.7046 - val_accuracy: 0.6810\n",
            "Epoch 193/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0314 - accuracy: 0.9764 - val_loss: 0.6610 - val_accuracy: 0.6665\n",
            "Epoch 194/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0319 - accuracy: 0.9774 - val_loss: 0.7117 - val_accuracy: 0.6560\n",
            "Epoch 195/200\n",
            "251/251 [==============================] - 22s 89ms/step - loss: 0.0410 - accuracy: 0.9677 - val_loss: 0.7691 - val_accuracy: 0.5906\n",
            "Epoch 196/200\n",
            "251/251 [==============================] - 22s 88ms/step - loss: 0.0366 - accuracy: 0.9728 - val_loss: 0.6909 - val_accuracy: 0.6700\n",
            "Epoch 197/200\n",
            "251/251 [==============================] - 22s 89ms/step - loss: 0.0338 - accuracy: 0.9726 - val_loss: 0.6847 - val_accuracy: 0.6505\n",
            "Epoch 198/200\n",
            "251/251 [==============================] - 22s 89ms/step - loss: 0.0323 - accuracy: 0.9802 - val_loss: 0.8919 - val_accuracy: 0.6805\n",
            "Epoch 199/200\n",
            "251/251 [==============================] - 22s 89ms/step - loss: 0.0313 - accuracy: 0.9773 - val_loss: 0.7184 - val_accuracy: 0.6855\n",
            "Epoch 200/200\n",
            "251/251 [==============================] - 22s 89ms/step - loss: 0.0271 - accuracy: 0.9820 - val_loss: 0.6950 - val_accuracy: 0.6615\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}