{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Boston_Hosing_L1_Regularization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YAOKjg-H3n5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDh-QaJSH8h-"
      },
      "source": [
        "# Load the dataset\n",
        "X, y = datasets.load_boston(return_X_y=True)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGMJyCHrIDEr"
      },
      "source": [
        "# Use only one feature.. Doing this heavily skews the MSE. \n",
        "# X = X[:, np.newaxis, 2] "
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNt-Vx46IH79"
      },
      "source": [
        "# Split the data into training/testing sets\n",
        "X_train, X_test, y_train, y_test=train_test_split(X,y,random_state=5,test_size=0.2) #ask dutton about this tomorrow!!\n",
        "\n",
        "# Old way to split dataset:\n",
        "# X_train = X[:-20]\n",
        "# X_test = X[-20:]\n",
        "# y_train = y[:-20]\n",
        "# y_test = y[-20:]"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N41ECIIsINgT"
      },
      "source": [
        "# Previous Code:\n",
        "# # Create linear regression object\n",
        "# regr = linear_model.LinearRegression()\n",
        "\n",
        "# New code to do L1 Regularization:\n",
        "regr = linear_model.Lasso(alpha=0.1)\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the testing set\n",
        "y_pred = regr.predict(X_test)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymCDD8n6IRW_",
        "outputId": "dd9a81df-9a93-42b0-bd4e-9a3bf8eab60f"
      },
      "source": [
        "# The coefficients\n",
        "print('Coefficients: \\n', regr.coef_)\n",
        "# The mean squared error\n",
        "print('Mean squared error: %.2f'\n",
        "      % mean_squared_error(y_test, y_pred))\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print('Coefficient of determination: %.2f'\n",
        "      % r2_score(y_test,y_pred))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coefficients: \n",
            " [-0.12292134  0.05415061 -0.0417807   0.82748267 -0.          3.1983821\n",
            " -0.00489453 -1.19598899  0.34055621 -0.01555885 -0.81475979  0.01213175\n",
            " -0.64983007]\n",
            "Mean squared error: 23.41\n",
            "Coefficient of determination: 0.70\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}