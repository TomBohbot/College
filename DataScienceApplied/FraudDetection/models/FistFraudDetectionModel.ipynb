{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FistFraudDetectionModel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiE2U1NeTCak"
      },
      "source": [
        "# Creating DataFrame and Necessary Import Statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7DqPOfrSWH3"
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pylab as plt\n",
        "from cycler import cycler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from fancyimpute import IterativeImputer\n",
        "from xgboost import XGBClassifier"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxpvE7GnSWzp",
        "outputId": "ad67fe48-cfe5-4892-a2b4-c9d412b3c279"
      },
      "source": [
        "!pip install kaggle --upgrade"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsqvpesPSYTP"
      },
      "source": [
        "!echo \"{\\\"username\\\":\\\"tombohorig\\\",\\\"key\\\":\\\"81f7fcd3a57da42eb3f3c20e0417fdfe\\\"}\" > kaggle.json"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-fO-ylwSoJp"
      },
      "source": [
        "!sudo mkdir -p ~/.kaggle\n",
        "!sudo cp /content/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0lnyg2bSp6r"
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1aPpzzWSqQy",
        "outputId": "347a9189-3bfa-432d-a39d-973920e71720"
      },
      "source": [
        "!kaggle --version"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle API 1.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyrQ-ns1SrfU",
        "outputId": "348e11a5-f205-415a-d5ab-5648e1e82538"
      },
      "source": [
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "train_transaction.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_transaction.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train_identity.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test_identity.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ7KHEeESyvj"
      },
      "source": [
        "np.random.seed(314159)\n",
        "train_txn = pd.read_csv('/content/train_transaction.csv.zip', compression='zip')\n",
        "train_id = pd.read_csv('/content/train_identity.csv.zip', compression='zip')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRPGxHMsS7qO",
        "outputId": "c2367c58-2847-4312-c0fc-2e8e1a2196a7"
      },
      "source": [
        "train_txn.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(590540, 394)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pPI5mqSS8Vm",
        "outputId": "23fd7a05-eeb8-4a97-c3a1-e981a66f3745"
      },
      "source": [
        "train_id.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(144233, 41)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtK9phbuuw9q"
      },
      "source": [
        "# Cleaning Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSuRhQaUuzcQ"
      },
      "source": [
        "### Drop columns with null values over a certain threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnULDOynu9Cz"
      },
      "source": [
        "def remove_heavy_null_columns(df, threshold, n_rows):\n",
        "  cols_over_threshold = []\n",
        "  for column in df:\n",
        "    missing_values = df[column].isna().sum()\n",
        "    if missing_values != 0 and missing_values/n_rows >= threshold:\n",
        "      cols_over_threshold.append(column)\n",
        "  df.drop(cols_over_threshold, axis=1, inplace=True)\n",
        "\n",
        "threshold = 0.5\n",
        "remove_heavy_null_columns(df=train_txn, threshold=threshold, n_rows=train_txn.shape[0])\n",
        "remove_heavy_null_columns(df=train_id, threshold=threshold, n_rows=train_txn.shape[0])"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjg_5AQVy09E"
      },
      "source": [
        "### Perform MICE Imputation on remaining Nan Cells\n",
        "After deciding to use a XGBoost Model and learning that it can deal with Nan Values and learn from them I will not impute these values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFHneSYDzh9u"
      },
      "source": [
        "# def fill_missing_values(df):\n",
        "#   # get all column names:\n",
        "#   print(df.head(20))\n",
        "#   column_names = df.columns\n",
        "#   # mice = IterativeImputer()\n",
        "#   # return pd.DataFrame(mice.fit_transform(df), columns=df.columns)\n",
        "\n",
        "# # print(\"BEFORE IMPUTATION:\")\n",
        "# # print(train_id.isna().sum())\n",
        "# # # print(penguins.isna().sum())\n",
        "\n",
        "# fill_missing_values(df=train_id)\n",
        "\n",
        "# # print()\n",
        "# # print(\"AFTER IMPUTATION:\")\n",
        "# # print(train_id.isna().sum())\n",
        "# # # print(penguins.isna().sum())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfyC8IiX8vt1"
      },
      "source": [
        "# Convert columns with String to be One Hot Encoded as converting to numeric in same column will give undesired order precedence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-7ABY5cGNOZ"
      },
      "source": [
        "# One hot encodings:\n",
        "def one_hot_encoding(df, column_name):\n",
        "  encoding = pd.get_dummies(df[column_name])\n",
        "  df = df.drop(column_name, axis = 1)\n",
        "  df = df.join(encoding)  \n",
        "  return df"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZgkWUP3GZNo"
      },
      "source": [
        "Preform Cleaning on train_id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4DE67xR85Hs",
        "outputId": "93dd3b43-e8ec-4cde-8da5-f430ffad0c62"
      },
      "source": [
        "# Transormations:\n",
        "boolean_found = {'NotFound': 0, 'Found': 1, None: 0}\n",
        "boolean_new = {'New': 0, 'Found': 1, None: 0}\n",
        "true_false = {'T': 2, 'F': 1, None: 0}\n",
        "device_type = {None: 0, 'mobile': 1, 'desktop': 2}\n",
        "train_id['id_12'].replace(boolean_found, inplace=True)\n",
        "train_id['id_16'].replace(boolean_found, inplace=True)\n",
        "train_id['id_27'].replace(boolean_found, inplace=True)\n",
        "train_id['id_28'].replace(boolean_new, inplace=True)\n",
        "train_id['id_29'].replace(boolean_found, inplace=True)\n",
        "train_id['id_35'].replace(true_false, inplace=True)\n",
        "train_id['id_36'].replace(true_false, inplace=True)\n",
        "train_id['id_37'].replace(true_false, inplace=True)\n",
        "train_id['id_38'].replace(true_false, inplace=True)\n",
        "train_id['DeviceType'].replace(device_type, inplace=True)\n",
        "\n",
        "# One Hot Encodings:\n",
        "train_id = one_hot_encoding(df=train_id, column_name='id_15')\n",
        "train_id = one_hot_encoding(df=train_id, column_name='id_23')\n",
        "train_id = one_hot_encoding(df=train_id, column_name='id_34')\n",
        "\n",
        "# I must drop instead of one hot encode b/c they make my df run out of ram:\n",
        "train_id = train_id.drop('id_30', axis=1) # I am dropping this column b/c it conflicts w/ id_31\n",
        "# train_id = one_hot_encoding(df=train_id, column_name='id_31')\n",
        "# train_id = one_hot_encoding(df=train_id, column_name='id_33')\n",
        "# train_id = one_hot_encoding(df=train_id, column_name='DeviceInfo')\n",
        "train_id = train_id.drop('id_31', axis=1)\n",
        "train_id = train_id.drop('id_33', axis=1)\n",
        "train_id = train_id.drop('DeviceInfo', axis=1)\n",
        "\n",
        "\n",
        "train_id.head(10)\n",
        "print(train_id.shape)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(144233, 44)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYqyn9i5GjRk"
      },
      "source": [
        "Preform Cleaning on Transactions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DanpuWFMGlf3",
        "outputId": "3368e211-5ae0-4d6f-993c-f15cd82c30f8"
      },
      "source": [
        "# Transormations:\n",
        "true_false = {'T': 2, 'F': 1, None: 0}\n",
        "train_txn['M1'].replace(true_false, inplace=True)\n",
        "train_txn['M2'].replace(true_false, inplace=True)\n",
        "train_txn['M3'].replace(true_false, inplace=True)\n",
        "train_txn['M6'].replace(true_false, inplace=True)\n",
        "\n",
        "# One Hot Encoding:\n",
        "train_txn = one_hot_encoding(df=train_txn, column_name='ProductCD')\n",
        "train_txn = one_hot_encoding(df=train_txn, column_name='card4')\n",
        "train_txn = one_hot_encoding(df=train_txn, column_name='card6')\n",
        "train_txn = one_hot_encoding(df=train_txn, column_name='P_emaildomain')\n",
        "\n",
        "# train_txn['R_emaildomain'] = 'RECIPIENT' + train_txn['R_emaildomain'].astype(str)\n",
        "# train_txn = one_hot_encoding(df=train_txn, column_name='R_emaildomain')\n",
        "\n",
        "train_txn['M4'] = 'M4 ' + train_txn['M4'].astype(str)\n",
        "train_txn = one_hot_encoding(df=train_txn, column_name='M4')\n",
        "\n",
        "train_txn.head(10)\n",
        "train_txn.shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(590540, 291)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjhzRGSk4_G_"
      },
      "source": [
        "# XGBoost Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VROb4r4o5H7Y"
      },
      "source": [
        "### Combine the models together and train/test split\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAg-Iq5s5KE0",
        "outputId": "a7f4d637-8ee5-48ce-c259-5df2614cccd1"
      },
      "source": [
        "# I've chosen an outer join b/c we previously discusses that it is better to not reduce the rows to the size of train_id but to keep the rows from train_txn:\n",
        "df = pd.merge(train_txn, train_id, on='TransactionID', how='inner')\n",
        "df.shape"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(144233, 334)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uuc7sDuY5xwu"
      },
      "source": [
        "# Train/Test Split:\n",
        "# split the dataset into train features and target varaible\n",
        "X = df.drop('isFraud', axis=1)\n",
        "y = df['isFraud']\n",
        "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZA2jSgNL5p4x"
      },
      "source": [
        "### Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq6GnSi85rzd",
        "outputId": "3bf94cb3-3d21-4dca-906a-f619981287a8"
      },
      "source": [
        "# Drop V columns even though we said theyre important in class. I just keep running out of RAM.\n",
        "v_columns = []\n",
        "for i in range (4,339):\n",
        "  try:\n",
        "    df.drop(f'V{i+1}')\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "print(df.shape)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(144233, 334)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQWgmsfjTvIv",
        "outputId": "05447159-c89d-4065-d968-7d3489f63aa5"
      },
      "source": [
        "# Create model:\n",
        "\n",
        "xgb_clf = XGBClassifier()\n",
        "xgb_clf.fit(train_x, train_y)\n",
        "# Print the accuracy score\n",
        "print(xgb_clf.score(test_x, test_y))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9565639407910701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onjvITfbW-YT",
        "outputId": "2b42a750-cd9c-487b-96e9-ab143a866c07"
      },
      "source": [
        "# Check if better then just guessing no every time:\n",
        "not_fraud, fraud = df['isFraud'].value_counts()\n",
        "fraud_propotion = fraud/not_fraud\n",
        "print(f\"The proportion of fraud is {fraud_propotion}.\")\n",
        "print(f\"My model is {0.9565639407910701-(1-fraud_propotion)} percent better than guessing yes every time.\")"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The proportion of fraud is 0.08515216491742843.\n",
            "My model is 0.041716105708498485 percent better than guessing yes every time.\n"
          ]
        }
      ]
    }
  ]
}